{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Directory containing images\n",
    "directory = 'data\\coco'\n",
    "\n",
    "# Get list of files in the directory\n",
    "files = os.listdir(directory)\n",
    "\n",
    "# Iterate through files and remove those with extensions other than .jpeg, .jpg, and .png\n",
    "for file in files:\n",
    "    if not file.lower().endswith(('.jpeg', '.jpg', '.png')):\n",
    "        os.remove(os.path.join(directory, file))\n",
    "        print(f\"Removed: {file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\zliya\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid OOM errors by setting GPU Memory Consumption Growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus: \n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def segment(image, threshold=25):\n",
    "    global bg\n",
    "    # find the absolute difference between background and current frame\n",
    "    diff = cv2.absdiff(bg.astype(\"uint8\"), image)\n",
    "\n",
    "    # threshold the diff image so that we get the foreground\n",
    "    thresholded = cv2.threshold(diff, threshold, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "    # get the contours in the thresholded image\n",
    "    (cnts, _) = cv2.findContours(thresholded.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # return None, if no contours detected\n",
    "    if len(cnts) == 0:\n",
    "        return\n",
    "    else:\n",
    "        # based on contour area, get the maximum contour which is the hand\n",
    "        segmented = max(cnts, key=cv2.contourArea)\n",
    "        return (thresholded, segmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\zliya\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\zliya\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 98, 118, 32)       320       \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 98, 118, 32)       128       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 49, 59, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 49, 59, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 47, 57, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 47, 57, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 23, 28, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 23, 28, 64)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 41216)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               5275776   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5295750 (20.20 MB)\n",
      "Trainable params: 5295558 (20.20 MB)\n",
      "Non-trainable params: 192 (768.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, BatchNormalization\n",
    "from keras.layers import Activation, Dropout\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "# model\n",
    "model = Sequential()\n",
    "\n",
    "# first conv layer\n",
    "# input shape = (img_rows, img_cols, 1)\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(100,120, 1))) \n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# second conv layer\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# flatten and put a fully connected layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu')) # fully connected\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# softmax layer\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "# model summary\n",
    "optimiser = Adam() \n",
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data\\\\coco\\\\0025.jpeg',\n",
       " 'data\\\\coco\\\\0028.jpeg',\n",
       " 'data\\\\coco\\\\0036.jpeg',\n",
       " 'data\\\\coco\\\\0041.jpeg',\n",
       " 'data\\\\coco\\\\0044.jpeg',\n",
       " 'data\\\\coco\\\\0056.jpeg',\n",
       " 'data\\\\coco\\\\0058.jpeg',\n",
       " 'data\\\\coco\\\\0060.jpeg',\n",
       " 'data\\\\coco\\\\0063.jpeg',\n",
       " 'data\\\\coco\\\\0073.jpeg',\n",
       " 'data\\\\coco\\\\0084.jpeg',\n",
       " 'data\\\\coco\\\\0090.jpeg',\n",
       " 'data\\\\coco\\\\0115.jpeg',\n",
       " 'data\\\\coco\\\\0117.jpeg',\n",
       " 'data\\\\coco\\\\0127.jpeg',\n",
       " 'data\\\\coco\\\\0130.jpeg',\n",
       " 'data\\\\coco\\\\0152.jpeg',\n",
       " 'data\\\\coco\\\\0157.jpeg',\n",
       " 'data\\\\coco\\\\0160.jpeg',\n",
       " 'data\\\\coco\\\\0165.jpeg',\n",
       " 'data\\\\coco\\\\0167.jpeg',\n",
       " 'data\\\\coco\\\\0169.png',\n",
       " 'data\\\\coco\\\\0175.jpeg',\n",
       " 'data\\\\coco\\\\0180.jpeg',\n",
       " 'data\\\\coco\\\\0194.jpeg',\n",
       " 'data\\\\coco\\\\0196.jpeg',\n",
       " 'data\\\\coco\\\\0206.jpeg',\n",
       " 'data\\\\coco\\\\0212.jpeg',\n",
       " 'data\\\\coco\\\\0225.jpeg',\n",
       " 'data\\\\coco\\\\0228.jpeg',\n",
       " 'data\\\\coco\\\\0231.jpeg',\n",
       " 'data\\\\coco\\\\0233.jpeg',\n",
       " 'data\\\\coco\\\\0250.jpeg',\n",
       " 'data\\\\coco\\\\0252.jpeg',\n",
       " 'data\\\\coco\\\\0255.jpeg',\n",
       " 'data\\\\coco\\\\0262.jpeg',\n",
       " 'data\\\\coco\\\\0268.jpeg',\n",
       " 'data\\\\coco\\\\0272.jpeg',\n",
       " 'data\\\\coco\\\\0273.jpeg',\n",
       " 'data\\\\coco\\\\0275.jpeg',\n",
       " 'data\\\\coco\\\\0277.jpeg',\n",
       " 'data\\\\coco\\\\0301.jpeg',\n",
       " 'data\\\\coco\\\\0304.jpeg',\n",
       " 'data\\\\coco\\\\0306.jpeg',\n",
       " 'data\\\\coco\\\\0315.jpeg',\n",
       " 'data\\\\coco\\\\0318.jpeg',\n",
       " 'data\\\\coco\\\\0320.jpeg',\n",
       " 'data\\\\coco\\\\0322.jpeg',\n",
       " 'data\\\\coco\\\\0328.jpeg',\n",
       " 'data\\\\coco\\\\0332.jpeg',\n",
       " 'data\\\\coco\\\\0335.jpeg',\n",
       " 'data\\\\coco\\\\0338.jpeg',\n",
       " 'data\\\\coco\\\\0356.jpeg',\n",
       " 'data\\\\coco\\\\0358.jpeg',\n",
       " 'data\\\\coco\\\\0361.jpeg',\n",
       " 'data\\\\coco\\\\0366.jpeg',\n",
       " 'data\\\\coco\\\\0369.jpeg',\n",
       " 'data\\\\coco\\\\0372.jpeg',\n",
       " 'data\\\\coco\\\\0376.jpeg',\n",
       " 'data\\\\coco\\\\0379.jpeg',\n",
       " 'data\\\\coco\\\\0391.jpeg',\n",
       " 'data\\\\coco\\\\0392.jpeg',\n",
       " 'data\\\\coco\\\\0394.jpeg',\n",
       " 'data\\\\coco\\\\0409.jpeg',\n",
       " 'data\\\\coco\\\\0413.jpeg',\n",
       " 'data\\\\coco\\\\0420.jpeg',\n",
       " 'data\\\\coco\\\\0427.jpeg']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "DATASET_PATH = 'data\\coco'\n",
    "\n",
    "dataset_path = os.path.join(DATASET_PATH, '*')\n",
    "import glob\n",
    "dataset_path = glob.glob(dataset_path)\n",
    "dataset_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the image using cv2.imread()\n",
    "image = cv2.imread(r'data\\coco\\0025.jpeg')\n",
    "\n",
    "# Check if the image is loaded successfully\n",
    "if image is not None:\n",
    "    # Resize the image\n",
    "    resized_image = cv2.resize(image, (100, 120))\n",
    "    # Display the resized image\n",
    "    cv2.imshow('Resized Image', resized_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print('Failed to load the image.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n",
      "(67, 293)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "loaded_images = []\n",
    "list_of_gestures = ['coco']\n",
    "\n",
    "for gesture in list_of_gestures:\n",
    "    dataset_path = \"data//\" + gesture\n",
    "    gesture_path = os.path.join(dataset_path, '*')\n",
    "    gest_path = glob.glob(gesture_path)\n",
    "    k = 0\n",
    "    for i in range(len(gest_path)):\n",
    "        if k < 1600:\n",
    "            image = cv2.imread(gest_path[i])\n",
    "            gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            gray_image = cv2.resize(gray_image, (100, 120))\n",
    "            loaded_images.append(gray_image)\n",
    "        k += 1\n",
    "\n",
    "print(len(loaded_images))\n",
    "\n",
    "num_classes = 293\n",
    "outputVectors = []\n",
    "\n",
    "for i in range(len(loaded_images)):\n",
    "    # Assuming your output vector needs to be all zeros except for one element set to 1\n",
    "    output_vector = np.zeros(num_classes)\n",
    "    output_vector[i % num_classes] = 1\n",
    "    outputVectors.append(output_vector)\n",
    "\n",
    "outputVectors = np.array(outputVectors)\n",
    "\n",
    "print(outputVectors.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67, 120, 100)\n",
      "(67, 293)\n",
      "(53, 100, 120, 1)\n",
      "(14, 100, 120, 1)\n"
     ]
    }
   ],
   "source": [
    "X = np.asarray(loaded_images)\n",
    "y = np.asarray(outputVectors)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4)\n",
    "X_train = X_train.reshape(X_train.shape[0], 100, 120, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 100, 120, 1)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
